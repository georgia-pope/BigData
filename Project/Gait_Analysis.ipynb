{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.preprocessing as preprocessing\n",
    "from sklearn import linear_model\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "X_male = np.load(\"Unify_Gait_Cycles/X_male.npy\")\n",
    "X_female = np.load(\"Unify_Gait_Cycles/X_female.npy\")\n",
    "label_male = [0]*X_male.shape[0]\n",
    "label_female = [1]*X_female.shape[0]\n",
    "num_male = X_male.shape[0]\n",
    "num_female = X_female.shape[0]\n",
    "gait_cycles = np.append(X_male, X_female, axis=0)\n",
    "labels = np.append(label_male, label_female, axis = 0)\n",
    "\n",
    "print(gait_cycles.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gait_cycles_acc = gait_cycles[:,:,3]\n",
    "poly_degree = 60\n",
    "\n",
    "indices = np.linspace(0,100,100,endpoint=False)\n",
    "indices = indices.T\n",
    "coeffs_list = []\n",
    "fits_list = []\n",
    "for i in range(gait_cycles.shape[0]):\n",
    "    cycle = gait_cycles_acc[i,:]\n",
    "    # NOTE Full=True to suppress warning that doesn't seem to be important\n",
    "    coeffs = np.polyfit(indices, cycle, poly_degree, full=True)[0]\n",
    "    poly_fit = np.poly1d(coeffs)\n",
    "    coeffs_list.append(coeffs)\n",
    "    fits_list.append(poly_fit)\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = 20\n",
    "\"\"\"\n",
    "for i in range(10):\n",
    "    plt.plot(indices, fits_list[i](indices))\n",
    "    plt.plot(indices, gait_cycles[i,:,3])\n",
    "    plt.show()\n",
    "\"\"\"\n",
    "kmeans_results = KMeans(n_clusters=num_clusters, random_state=0, n_init=poly_degree+1).fit(coeffs_list)\n",
    "# mult_vals = X@(kmeans.cluster_centers_[1].T)\n",
    "# print(mult_vals)\n",
    "\n",
    "print(\"Starting final for loop\")\n",
    "for i in range(num_clusters):\n",
    "    male_count = 0\n",
    "    female_count = 0\n",
    "    cluster = np.where(i == kmeans_results.labels_)[0]\n",
    "    centroid_fit = np.poly1d(kmeans_results.cluster_centers_[i].T)\n",
    "    print(len(cluster))\n",
    "    for j in range(len(cluster)):\n",
    "        if cluster[j] < num_male:\n",
    "            male_count += 1\n",
    "            color = 'r'\n",
    "            #plt.plot(range(0,100),gait_cycles[cluster[j],:,3], 'r--')\n",
    "        else:\n",
    "            female_count += 1\n",
    "            color = 'b'\n",
    "            #plt.plot(range(0,100),gait_cycles[cluster[j],:,3], 'b--')\n",
    "        if j % 10 == 0:\n",
    "            plt.plot(range(0,100),gait_cycles[cluster[j],:,3], color + '--')\n",
    "    print(\"Num Males: \", male_count)\n",
    "    print(\"Num Females: \", female_count)\n",
    "    plt.plot(indices, centroid_fit(indices), 'g-')\n",
    "    plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the data\n",
    "perm = np.random.permutation(gait_cycles.shape[0])\n",
    "gait_cycles = gait_cycles[perm]\n",
    "labels = labels[perm]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gait_ind_cycles = gait_cycles\n",
    "num_measurements = gait_ind_cycles.shape[1]\n",
    "ax_bar = np.sum(gait_ind_cycles[:,:,0],axis=1)/num_measurements\n",
    "ay_bar = np.sum(gait_ind_cycles[:,:,1],axis=1)/num_measurements\n",
    "az_bar = np.sum(gait_ind_cycles[:,:,2],axis=1)/num_measurements\n",
    "\n",
    "# Gravity vector\n",
    "rho_list = np.array([ax_bar, ay_bar, az_bar]).T\n",
    "\n",
    "# Normalized gravity vector \n",
    "zeta = rho_list / np.reshape(np.repeat(np.linalg.norm(rho_list, axis=1), 3, axis=0), (9968, 3))\n",
    "\n",
    "# Acceleration matrix\n",
    "A = gait_ind_cycles[:,:,0:3]\n",
    "\n",
    "# Finding acceleration in up down direction\n",
    "a_zeta = []\n",
    "for i in range(zeta.shape[0]):\n",
    "    sample_a_zeta = []\n",
    "    for row in A[i]:\n",
    "        A_g = np.dot(row,zeta[i])\n",
    "        sample_a_zeta.append(A_g)\n",
    "    a_zeta.append(sample_a_zeta)\n",
    "a_zeta = np.array(a_zeta)\n",
    "print(a_zeta.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find acceleration in flattened plane (without up down)\n",
    "zeta_repeat = np.repeat(zeta, 100, axis=0)\n",
    "zeta_repeat = np.reshape(zeta_repeat, (9968, 100, 3))\n",
    "a_zeta_repeat = np.repeat(a_zeta, 3, axis=1)\n",
    "a_zeta_repeat = np.reshape(a_zeta_repeat, (-1, 100,3))\n",
    "\n",
    "A_f = A - zeta_repeat*a_zeta_repeat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using PCA to find first principle direction (forward and back)\n",
    "xi = []\n",
    "for person in A_f:\n",
    "    pca = PCA(n_components=1)\n",
    "    pca.fit(person)\n",
    "    xi.append(pca.components_)\n",
    "xi = np.array(xi)\n",
    "xi = np.reshape(xi, (-1,3))\n",
    "\n",
    "# Extract acceleration in the xi direction\n",
    "a_xi = []\n",
    "for i in range(xi.shape[0]):\n",
    "    sample_a_xi = []\n",
    "    for row in A_f[i]:\n",
    "        A_xi = np.dot(row,xi[i])\n",
    "        sample_a_xi.append(A_xi)\n",
    "    a_xi.append(sample_a_xi)\n",
    "a_xi = np.array(a_xi)\n",
    "print(a_xi.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use cross product to find third direction (right and left)\n",
    "psi = np.cross(zeta,xi, axis=1)\n",
    "print(psi.shape)\n",
    "\n",
    "# Extract acceleration in the psi direction\n",
    "a_psi = []\n",
    "for i in range(psi.shape[0]):\n",
    "    sample_a_psi = []\n",
    "    for row in A_f[i]:\n",
    "        A_psi = np.dot(row,psi[i])\n",
    "        sample_a_psi.append(A_psi)\n",
    "    a_psi.append(sample_a_psi)\n",
    "a_psi = np.array(a_psi)\n",
    "print(a_psi.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make new ndarray with new coordinate system\n",
    "\n",
    "A_transformed = np.stack((a_zeta, a_xi, a_psi), axis = 2)\n",
    "A_trans_mag = np.linalg.norm(A_transformed, axis=2)\n",
    "A_transformed = np.stack((a_zeta, a_xi, a_psi,A_trans_mag), axis = 2)\n",
    "\n",
    "#to_show = 6\n",
    "to_show = 8\n",
    "#to_show = 11\n",
    "#to_show = 20\n",
    "plt.figure(1)\n",
    "plt.subplot(211)\n",
    "plt.plot(range(0,100), A_transformed[to_show,:,0], color='orange')\n",
    "plt.ylabel('zeta')\n",
    "plt.subplot(212)\n",
    "plt.plot(range(0,100), A_transformed[to_show,:,1], color='orange')\n",
    "plt.ylabel('xi')\n",
    "plt.figure(2)\n",
    "plt.subplot(211)\n",
    "plt.plot(range(0,100), A_transformed[to_show,:,2], color='orange')\n",
    "plt.ylabel('psi')\n",
    "plt.subplot(212)\n",
    "plt.plot(range(0,100), A_transformed[to_show,:,3], color='orange')\n",
    "plt.ylabel('magnitude')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(0,100), A_transformed[to_show,:,0], color='orange')\n",
    "plt.title(\"zeta\")\n",
    "plt.figure()\n",
    "plt.plot(range(0,100), A_transformed[to_show,:,1], color='orange')\n",
    "plt.title(\"xi\")\n",
    "plt.figure()\n",
    "plt.plot(range(0,100), A_transformed[to_show,:,2], color='orange')\n",
    "plt.title(\"psi\")\n",
    "plt.figure()\n",
    "plt.plot(range(0,100), A_transformed[to_show,:,3], color='orange')\n",
    "plt.title(\"Magnitude\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gait_cycles_x = gait_cycles[:,:,0]\n",
    "\n",
    "poly = preprocessing.PolynomialFeatures(10)\n",
    "indices = np.linspace(0,100,100, endpoint=False)\n",
    "indices = indices.T\n",
    "X = poly.fit_transform(indices.reshape(-1,1))\n",
    "print(X.shape)\n",
    "lm_array = np.ndarray((9968,11))\n",
    "\n",
    "lm_object_array = []\n",
    "for i in range(gait_cycles.shape[0]):\n",
    "    cycle = gait_cycles[i,:,3]     \n",
    "    lm = linear_model.LinearRegression(fit_intercept=True)\n",
    "    model = lm.fit(X,cycle)\n",
    "    lm_array[i,:] = model.coef_\n",
    "    lm_object_array.append(model)\n",
    "#     plt.plot(indices,model.predict(X))\n",
    "#     plt.plot(indices, gait_cycles[i,:,3])\n",
    "#     plt.show()\n",
    "\n",
    "# print(lm_array.shape)\n",
    "# kmeans = KMeans(n_clusters=20, random_state=0, n_init=20).fit(lm_array)\n",
    "# print(kmeans.labels_)\n",
    "\n",
    "# inertia_array = []\n",
    "# for i in range(1,15):\n",
    "#     kmeans_i = kmeans = KMeans(n_clusters=i, random_state=0, n_init=20).fit(lm_array)\n",
    "#     inertia_array.append(kmeans_i.inertia_)\n",
    "# plt.plot(range(1,15),inertia_array)\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "kmeans = KMeans(n_clusters=10, random_state=0, n_init=20).fit(lm_array)\n",
    "# for i in range(10):\n",
    "#     plt.plot(indices, X@lm_array[i].T)\n",
    "#     plt.plot(indices, gait_cycles[i,:,3])\n",
    "#     plt.show()\n",
    "\n",
    "# mult_vals = X@(kmeans.cluster_centers_[1].T)\n",
    "# print(mult_vals)\n",
    "\n",
    "print(\"Starting final for loop\")\n",
    "for i in range(10):\n",
    "    cluster = np.where(i == kmeans.labels_)[0]\n",
    "    plot_vals = X@(kmeans.cluster_centers_[i].T)\n",
    "    plt.plot(indices, plot_vals)\n",
    "    plt.show()\n",
    "    for j in cluster:\n",
    "        \n",
    "        plt.plot(range(0,100),gait_cycles[j,:,3], 'b-')\n",
    "#         plt.plot(range(0,100), mean_array)\n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_validate = 1004\n",
    "num_validate = 500\n",
    "gait_cycles_train = gait_cycles[0:-num_validate]\n",
    "gait_cycles_test = gait_cycles[-num_validate:]\n",
    "\n",
    "# gait_cycles_train = A_transformed[0:-num_validate]\n",
    "# gait_cycles_test = A_transformed[-num_validate:]\n",
    "\n",
    "labels_train = labels[0:-num_validate]\n",
    "labels_test = labels[-num_validate:]\n",
    "# Make them nice tensors :)\n",
    "batch_size = 9\n",
    "# gait_cycles_train = torch.FloatTensor(gait_cycles_train[:,:,3]).reshape(-1,batch_size,1,100)\n",
    "# gait_cycles_test = torch.FloatTensor(gait_cycles_test[:,:,3]).reshape(-1,1,1,100)\n",
    "# labels_train = torch.LongTensor(labels_train).reshape(-1,batch_size)\n",
    "# labels_test = torch.LongTensor(labels_test).reshape(-1, 1)\n",
    "gait_cycles_train = torch.FloatTensor(gait_cycles_train).permute(0,2,1).reshape(1052,batch_size,4,100)\n",
    "gait_cycles_test = torch.FloatTensor(gait_cycles_test).permute(0,2,1).reshape(500,1,4,100)\n",
    "labels_train = torch.LongTensor(labels_train).reshape(-1,batch_size)\n",
    "labels_test = torch.LongTensor(labels_test).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    \n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gait_Classifier(nn.Module):\n",
    "    \"\"\"\n",
    "    TODO: Add attention\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size=100, kernel_size=10, hidden_size=500):\n",
    "        super(Gait_Classifier, self).__init__()\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "        self.lstm_encoder = nn.LSTM(100, 100,2)\n",
    "       # self.layers.append(nn.Conv1d(1, 20, kernel_size))\n",
    "        self.layers.append(nn.Sequential(\n",
    "            nn.Conv1d(4, 25, kernel_size),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2)))\n",
    "        self.layers.append(nn.Sequential(\n",
    "            nn.Conv1d(25, 50, kernel_size),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)))\n",
    "        self.layers.append(nn.Dropout(0.1))\n",
    "        self.layers.append(Flatten())\n",
    "        self.layers.append(nn.Linear(25*18, hidden_size))\n",
    "        self.layers.append(nn.ReLU())\n",
    "        self.layers.append(nn.Linear(hidden_size, 2))\n",
    "        self.layers.append(nn.Softmax(dim=1))\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        #out = self.lstm_encoder(x)[0]\n",
    "        out = x\n",
    "        for layer in self.layers:\n",
    "            out = layer(out)\n",
    "        return out\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size=100, kernel_size=10, hidden_size=500):\n",
    "        super(Gait_Classifier, self).__init__()\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "        self.lstm_encoder = nn.LSTM(100, 20)\n",
    "       # self.layers.append(nn.Conv1d(1, 20, kernel_size))\n",
    "        self.layers.append(nn.Sequential(\n",
    "            nn.Conv1d(4, 20, kernel_size),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2)))\n",
    "        self.layers.append(nn.Sequential(\n",
    "            nn.Conv1d(20, 40, kernel_size),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)))\n",
    "        self.layers.append(nn.Dropout(0.1))\n",
    "        self.layers.append(Flatten())\n",
    "        self.layers.append(nn.Linear(20*18, hidden_size))\n",
    "        self.layers.append(nn.ReLU())\n",
    "        self.layers.append(nn.Linear(hidden_size, 2))\n",
    "        self.layers.append(nn.Softmax(dim=1))\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        print(x.shape)\n",
    "        out = self.lstm_encoder(x)\n",
    "        for layer in self.layers:\n",
    "            out = layer(out)\n",
    "        return out\n",
    "\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://adventuresinmachinelearning.com/convolutional-neural-networks-tutorial-in-pytorch/ Helped a lot!\n",
    "\n",
    "def train_model(model, optimizer, x_train, y_train, x_test, y_test, batch_size, num_epochs=20):\n",
    "    loss_list = []\n",
    "    acc_list = []\n",
    "    total_step = len(x_train)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    correct = 0.0\n",
    "    model = model.eval()\n",
    "    validation_loss = 0\n",
    "    for (test_gait, test_lab) in zip(x_test, y_test):\n",
    "        prediction = model(test_gait)\n",
    "        validation_loss += criterion(prediction, test_lab)\n",
    "        if prediction.argmax() == test_lab:\n",
    "            correct += 1.0\n",
    "    acc = correct / y_test.size()[0]\n",
    "    acc_list.append(acc)\n",
    "    validation_loss /= x_test.shape[0]\n",
    "    loss_list.append(validation_loss)\n",
    "    model = model.train()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (gaits, labels) in enumerate(zip(x_train, y_train)):\n",
    "            # Run the forward pass\n",
    "            outputs = model(gaits)\n",
    "            loss = criterion(outputs, labels)\n",
    "            #loss_list.append(loss.item())\n",
    "\n",
    "            # Backprop and perform Adam optimisation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Track the accuracy\n",
    "            total = labels.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct = (predicted == labels).sum().item()\n",
    "            # acc_list.append(correct / total)\n",
    "            if (i + 1) % 1000 == 0:\n",
    "                correct = 0.0\n",
    "                model = model.eval()\n",
    "                validation_loss = 0\n",
    "                for (test_gait, test_lab) in zip(x_test, y_test):\n",
    "                    prediction = model(test_gait)\n",
    "                    validation_loss += criterion(prediction, test_lab)\n",
    "                    if prediction.argmax() == test_lab:\n",
    "                        correct += 1.0\n",
    "                acc = correct / y_test.size()[0]\n",
    "                acc_list.append(acc)\n",
    "                validation_loss /= x_test.shape[0]\n",
    "                loss_list.append(validation_loss)\n",
    "                model = model.train()\n",
    "                    \n",
    "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, validation_loss,\n",
    "                              acc * 100))\n",
    "        \n",
    "    correct = 0.0\n",
    "    model = model.eval()\n",
    "    validation_loss = 0\n",
    "    for (test_gait, test_lab) in zip(x_test, y_test):\n",
    "        prediction = model(test_gait)\n",
    "        validation_loss += criterion(prediction, test_lab)\n",
    "        if prediction.argmax() == test_lab:\n",
    "            correct += 1.0\n",
    "    acc = correct / y_test.size()[0]\n",
    "    acc_list.append(acc)\n",
    "    validation_loss /= x_test.shape[0]\n",
    "    loss_list.append(validation_loss)\n",
    "    model = model.train()\n",
    "    return loss_list, acc_list\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc = Gait_Classifier()\n",
    "learning_rate = 3e-5\n",
    "optimizer = torch.optim.Adam(gc.parameters(), lr=learning_rate)\n",
    "(loss, acc) = train_model(gc, optimizer, gait_cycles_train, labels_train, gait_cycles_test, labels_test, 9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0.0\n",
    "gc = gc.eval()\n",
    "validation_loss = 0\n",
    "for (batch_test_gaits, batch_test_labs) in zip(gait_cycles_train, labels_train):\n",
    "    #print(batch_test_gaits.shape)\n",
    "    for (test_gait, test_lab) in zip (batch_test_gaits, batch_test_labs):\n",
    "        #print(test_gait.shape)\n",
    "        prediction = gc(test_gait.unsqueeze(0))\n",
    "        #validation_loss += criterion(prediction, test_lab)\n",
    "        if prediction.argmax() == test_lab:\n",
    "            correct += 1.0\n",
    "acc = correct / (labels_train.size()[0]*9)\n",
    "print(acc)\n",
    "print(labels_train.size()[0])\n",
    "#acc_list.append(acc)\n",
    "#validation_loss /= x_test.shape[0]\n",
    "#loss_list.append(validation_loss)\n",
    "gc = gc.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(acc)),acc)\n",
    "plt.title('Classification Accuracy as a Function of Epoch')\n",
    "plt.ylabel('% Accuracy')\n",
    "plt.xlabel(\"Epoch\")\n",
    "#plt.savefig(\"classification_accuracy_Test.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(loss, acc) = train_model(gc, optimizer, gait_cycles_train, labels_train, gait_cycles_test, labels_test, 1, num_epochs=20)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_indices = []\n",
    "for i in range(len(labels_test)):\n",
    "    if gc(gait_cycles_test[i]).argmax() != labels_test[i]:\n",
    "        wrong_indices.append(i)\n",
    "\n",
    "gait_cycles_numpy = gait_cycles[-500:]\n",
    "for i in wrong_indices:\n",
    "    one_person = gait_cycles_numpy[i]\n",
    "    t = range(one_person.shape[0])\n",
    "    mag = one_person[:,3]\n",
    "    plt.plot(t,mag)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(gc.state_dict(), 'model_new.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc = torch.load('model.pt')\n",
    "gc.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
